{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9s1j6Yvh5ie_"
      },
      "outputs": [],
      "source": [
        "from fundAccess import searchEdgarFund,searchEdgarNCSR\n",
        "from secReportSweeping import filingSplitPages, searchPagesForPatterns, savePagesTuples, associateFilingPagesToElements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB-zkGC5nwf0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "!pip install pyhtml2pdf\n",
        "!pip install pdfkit\n",
        "!pip install PyMuPDF # this will allow you to use fitz\n",
        "import fitz\n",
        "import pandas as pd\n",
        "#!pip install wkhtmltopdf\n",
        "!sudo apt-get install wkhtmltopdf\n",
        "!pip install PyPDF2\n",
        "!pip install rank-bm25\n",
        "!apt-get update\n",
        "#!wget https://github.com/wkhtmltopdf/packaging/releases/download/0.12.6.1-2/wkhtmltox_0.12.6.1-2.jammy_amd64.deb\n",
        "#!apt install /content/wkhtmltox_0.12.6.1-2.jammy_amd64.deb && rm /content/wkhtmltox_0.12.6.1-2.jammy_amd64.deb\n",
        "%pip install anytree\n",
        "from anytree import Node, RenderTree\n",
        "from rank_bm25 import BM25Okapi\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "!pip install rouge\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRmhB_yZv2M5"
      },
      "source": [
        "## Main Functions\n",
        "run it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R19J3AnXn4J3",
        "outputId": "b5f39a82-e96c-4710-e901-bf1c869aca96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from rank_bm25 import BM25Okapi\n",
        "from itertools import islice\n",
        "import PyPDF2\n",
        "import pdfkit\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Tokenization\n",
        "def tokenize(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    return [word for word in words if word.isalnum()]\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([word for word in text.split() if word.lower() not in stop_words])\n",
        "\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "def stem_text(text):\n",
        "    return ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "# Preprocessing pipeline\n",
        "def preprocess(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove punctuation and special characters\n",
        "    text = ''.join(char for char in text if char.isalnum() or char.isspace())\n",
        "\n",
        "    # Remove stopwords\n",
        "    text = remove_stopwords(text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def cleaning(aText):\n",
        "\n",
        "    #remove not some not alphanumeric character\n",
        "    t  = re.sub(\"[^a-zA-Z0-9_\\s\\-%.&\\,:;@\\(\\)$\\x92\\'\\ʼ\\ʻ\\’\\\\\\/\\*]\", ' ', aText)\n",
        "\n",
        "    #substitute line break by space\n",
        "    t  = re.sub(\"\\n+\", \" \", t )\n",
        "\n",
        "    #combine multiple space into 1 space\n",
        "    t = re.sub(\"\\s+\", \" \", t )\n",
        "\n",
        "    t  = re.sub(\"\\xa0+\", \" \", t )\n",
        "\n",
        "    t = t.strip()\n",
        "\n",
        "    #'\n",
        "    #t  = re.sub(\"\\x92\", \"'\", t )\n",
        "\n",
        "    #remove ascii\n",
        "    #t = re.sub(r'[^\\x00-\\x7F]', ' ', t)\n",
        "\n",
        "    return t\n",
        "\n",
        "def get_report(url,name='result'):\n",
        "  # URL of the HTML report\n",
        "  url = url\n",
        "\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "  response = requests.get(url,headers=headers)\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Parse the HTML content using BeautifulSoup\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "\n",
        "      with open(name+'.html','w') as f:\n",
        "        f.write(response.text)\n",
        "\n",
        "\n",
        "      with open(name+'.html','r') as f:\n",
        "        s = f.read()\n",
        "\n",
        "\n",
        "      # path_wkhtmltopdf = '/usr/bin/wkhtmltopdf'\n",
        "      x = !whereis wkhtmltopdf\n",
        "      path_wkhtmltopdf = x[0].split(\": \")[-1]\n",
        "      config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
        "\n",
        "      try:\n",
        "        pdfkit.from_string(s, name+'.pdf', configuration=config)\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "\n",
        "      pdf_file_path = name+'.pdf'\n",
        "\n",
        "      # split pdf into pages\n",
        "      # Open the PDF file in read-binary mode\n",
        "      with open(pdf_file_path, 'rb') as pdf_file:\n",
        "          # Create a PDF reader object\n",
        "          pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "          # Get the total number of pages in the PDF\n",
        "          num_pages = len(pdf_reader.pages)\n",
        "\n",
        "          pages_str = {}\n",
        "          # Loop through each page\n",
        "          for page_number in range(num_pages):\n",
        "\n",
        "              page = pdf_reader.pages[page_number]\n",
        "\n",
        "              # Extract text from the page (you can do other operations here)\n",
        "              page_text = page.extract_text()\n",
        "\n",
        "              # Print or process the page text as needed\n",
        "              #print(f\"Page {page_number + 1}:\\n{page_text}\\n\")\n",
        "              pages_str[page_number] = page_text\n",
        "              #pages_str.append(page_text)\n",
        "\n",
        "      return pages_str\n",
        "  else:\n",
        "      print('Failed to fetch the HTML content.')\n",
        "\n",
        "\n",
        "def report_from_url(url,name):\n",
        "  \"\"\" download webpage as html \"\"\"\n",
        "  headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "  response = requests.get(url,headers=headers)\n",
        "\n",
        "  # Check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "      # Parse the HTML content using BeautifulSoup\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "\n",
        "      with open(name+'.html','w') as f:\n",
        "        f.write(response.text)\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "def pdf_from_url(url, name=\"output\"):\n",
        "    \"\"\"Download webpage as a PDF file directly.\"\"\"\n",
        "    try:\n",
        "        counter = 1\n",
        "        pdf_name = f'{name}.pdf'\n",
        "\n",
        "        # # Check if the file already exists\n",
        "        # while os.path.exists(pdf_name):\n",
        "        #     pdf_name = f'{name}_{counter}.pdf'\n",
        "        #     counter += 1\n",
        "\n",
        "        # Convert webpage to PDF\n",
        "        pdfkit.from_url(url, pdf_name)\n",
        "\n",
        "        print(f'PDF created successfully: {pdf_name}')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unable to create PDF from webpage. Error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def dict_from_pdf(pdf_file_path):\n",
        "  \"\"\" read text data from pdf file directly into dictonary of page_number:content \"\"\"\n",
        "  # split pdf into pages\n",
        "  # Open the PDF file in read-binary mode\n",
        "  with open(pdf_file_path, 'rb') as pdf_file:\n",
        "      # Create a PDF reader object\n",
        "      pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "      # Get the total number of pages in the PDF\n",
        "      num_pages = len(pdf_reader.pages)\n",
        "\n",
        "      pages_str = {}\n",
        "      # Loop through each page\n",
        "      for page_number in range(num_pages):\n",
        "\n",
        "          page = pdf_reader.pages[page_number]\n",
        "\n",
        "          # Extract text from the page (you can do other operations here)\n",
        "          page_text = page.extract_text()\n",
        "\n",
        "          # Print or process the page text as needed\n",
        "          #print(f\"Page {page_number + 1}:\\n{page_text}\\n\")\n",
        "          pages_str[page_number] = page_text\n",
        "          #pages_str.append(page_text)\n",
        "\n",
        "  return pages_str\n",
        "\n",
        "\n",
        "  import fitz  # PyMuPDF\n",
        "\n",
        "def extract_relevant_page_numbers(pdf_file_path, wanted_funds, unwanted_funds):\n",
        "    relevant_page_numbers = []\n",
        "    current_page_relevant = False  # Set the relevant flag to True from the beginning\n",
        "\n",
        "    if type(wanted_funds) is not list:\n",
        "      wanted_funds = [wanted_funds]\n",
        "    if type(unwanted_funds) is not list:\n",
        "      unwanted_funds = [unwanted_funds]\n",
        "\n",
        "    # Open the PDF file\n",
        "    pdf_document = fitz.open(pdf_file_path)\n",
        "\n",
        "    if len(unwanted_funds) == 0:\n",
        "      return [i for i in range(pdf_document.page_count)]\n",
        "\n",
        "    wanted_funds = [fund.lower() for fund in wanted_funds]\n",
        "    wanted_funds = [re.sub(\"[^a-z0-9\\s]\",'',fund) for fund in wanted_funds]\n",
        "    unwanted_funds = [fund.lower() for fund in unwanted_funds]\n",
        "    unwanted_funds = [re.sub(\"[^a-z0-9\\s]\",'',fund) for fund in unwanted_funds]\n",
        "\n",
        "    for page_number in range(pdf_document.page_count):\n",
        "        page = pdf_document.load_page(page_number)\n",
        "        text = page.get_text(\"text\").lower()\n",
        "        text = re.sub(\"[^a-z0-9\\s]\",'',text)\n",
        "\n",
        "        # Check if any wanted fund is in the page\n",
        "        if any(fund in text for fund in wanted_funds):\n",
        "          current_page_relevant = True\n",
        "\n",
        "        # Check if no wanted funds are present but unwanted funds are\n",
        "        if not any(fund in text for fund in wanted_funds) and any(fund in text for fund in unwanted_funds):\n",
        "          current_page_relevant = False\n",
        "\n",
        "        # If the page is considered relevant, add its number to the list\n",
        "        if current_page_relevant:\n",
        "          relevant_page_numbers.append(page_number)\n",
        "\n",
        "        # Check if any unwanted fund is in the page\n",
        "        if any(fund in text for fund in unwanted_funds):\n",
        "            current_page_relevant = False\n",
        "\n",
        "    # Close the PDF document\n",
        "    pdf_document.close()\n",
        "\n",
        "    return relevant_page_numbers\n",
        "\n",
        "\n",
        "import os\n",
        "def pdf_fundpages(url,wanted,unwanted,name=\"output\"):\n",
        "    \"\"\"Download webpage as a PDF file directly.\"\"\"\n",
        "    try:\n",
        "        counter = 1\n",
        "        pdf_name = f'{name}.pdf'\n",
        "\n",
        "        # Convert webpage to PDF\n",
        "        pdfkit.from_url(url, pdf_name)\n",
        "\n",
        "        fund_pages = extract_relevant_page_numbers(pdf_name,wanted,unwanted)\n",
        "\n",
        "        extract_pages(pdf_name,pdf_name,fund_pages)\n",
        "\n",
        "        print(f'PDF created successfully: {pdf_name}')\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Unable to create PDF from webpage. Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "C0da-yrwoVtp"
      },
      "outputs": [],
      "source": [
        "# use bm25 and get top_k pages\n",
        "def get_relevant(pages_str,query,top_k):\n",
        "\n",
        "  # Tokenize the documents (you can use more advanced tokenization methods)\n",
        "  preprocessed_pages = {index:preprocess(page) for index,page in pages_str.items()}\n",
        "  tokenized_pages = [doc.split() for doc in preprocessed_pages.values()]\n",
        "\n",
        "  # Create a BM25 index\n",
        "  bm25 = BM25Okapi(tokenized_pages)\n",
        "\n",
        "  # Sample query\n",
        "  query = query\n",
        "\n",
        "  # Tokenize the query\n",
        "  query = preprocess(query)\n",
        "  tokenized_query = query.split()\n",
        "\n",
        "  # Get BM25 scores for the query\n",
        "  scores = bm25.get_scores(tokenized_query)\n",
        "\n",
        "  # Rank documents by their BM25 scores\n",
        "  ranked_indices = sorted(range(len(scores)), key=lambda i: -scores[i])\n",
        "  ranked_documents = {pages_str[i]:scores[i] for i in ranked_indices}\n",
        "\n",
        "  # Print top k ranked documents\n",
        "  #top_k = 5\n",
        "  top_k = top_k\n",
        "  res = dict(islice(ranked_documents.items(), top_k))\n",
        "\n",
        "  return dict(zip(ranked_indices[:top_k],sorted(scores,reverse=True)[:top_k]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c9_y4y-4oXbJ"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "def extract_pages(input_pdf, output_pdf, page_numbers):\n",
        "    try:\n",
        "        # Open the input PDF file\n",
        "        with open(input_pdf, 'rb') as pdf_file:\n",
        "            pdf = PyPDF2.PdfReader(pdf_file)\n",
        "            pdf_writer = PyPDF2.PdfWriter ()\n",
        "\n",
        "            # Check if the specified page numbers are valid\n",
        "            valid_page_numbers = [page for page in page_numbers if 0 <= page < len(pdf.pages)]\n",
        "\n",
        "            valid_page_numbers.sort()\n",
        "\n",
        "            if not valid_page_numbers:\n",
        "                print(\"No valid page numbers specified.\")\n",
        "                return\n",
        "\n",
        "            # Add the specified pages to the new PDF\n",
        "            for page in valid_page_numbers:\n",
        "                pdf_writer.add_page(pdf.pages[page])\n",
        "\n",
        "            # Write the selected pages to the output PDF\n",
        "            with open(output_pdf, 'wb') as output_file:\n",
        "                pdf_writer.write(output_file)\n",
        "\n",
        "            print(f\"Selected pages saved to {output_pdf}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e-JcTqIM2cBa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTvK8ZBsXdBE",
        "outputId": "79f00bb4-ac42-406c-e80c-afd5c276abb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def calculate_recall(reference_text, predicted_text):\n",
        "    reference_tokens = set(word_tokenize(reference_text.lower()))\n",
        "    predicted_tokens = set(word_tokenize(predicted_text.lower()))\n",
        "\n",
        "    true_positives = len(reference_tokens.intersection(predicted_tokens))\n",
        "    false_negatives = len(reference_tokens - predicted_tokens)\n",
        "\n",
        "    recall = true_positives / (true_positives + false_negatives)\n",
        "    return recall\n",
        "\n",
        "def calculate_precision(reference_text, predicted_text):\n",
        "    reference_tokens = set(word_tokenize(reference_text.lower()))\n",
        "    predicted_tokens = set(word_tokenize(predicted_text.lower()))\n",
        "\n",
        "    true_positives = len(reference_tokens.intersection(predicted_tokens))\n",
        "    false_positives = len(predicted_tokens - reference_tokens)\n",
        "\n",
        "    precision = true_positives / (true_positives + false_positives)\n",
        "    return precision\n",
        "\n",
        "def select_two_pages(max_ranking_df):\n",
        "  max_ranking_df = max_ranking_df.sort_values(by='page_num') # expand nodes to get childrens first ->  not done\n",
        "  filtered_df = pd.DataFrame()\n",
        "  for index,row in max_ranking_df.iterrows():\n",
        "    expanded_df = pd.DataFrame({node.text:row.node.page_num for node in get_all_nodes_under(row.node)[1:]}.items(),columns=['node_text','page_num']) # expand each row node to get all its children\n",
        "    filtered_df = pd.concat([filtered_df,expanded_df],ignore_index=False)\n",
        "\n",
        "  head_2 = []\n",
        "  for index,row in filtered_df.iterrows():\n",
        "      if len(np.unique(head_2)) == 2 and row['page_num'] not in head_2:\n",
        "        break\n",
        "      else:\n",
        "        head_2.append(row['page_num'])\n",
        "\n",
        "  result_df = max_ranking_df[max_ranking_df['page_num'].isin(head_2)]\n",
        "  return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XdMivpgCVzaV"
      },
      "outputs": [],
      "source": [
        "#list of markers and identifiers (structure of text file is known beforehad)\n",
        "markers =  [\"Reporting_Date\",\n",
        "            \"Table_Contents\",\n",
        "            \"Letter_CEO\",\n",
        "            \"Letter_CEO_Title\",\n",
        "            \"Letter_SM\",\n",
        "            \"Letter_SM_Title\",\n",
        "            \"Letter_GEC\",\n",
        "            \"Letter_MDFP\",\n",
        "            \"GEC\",\n",
        "            \"GEC_Title\",\n",
        "            \"MDFP\",\n",
        "            \"MDFP_Title\",\n",
        "            \"MDFP_GEC\",\n",
        "            \"Comments_RA\"]\n",
        "\n",
        "identifiers = [\"Line_Number\", \"Series\"]\n",
        "\n",
        "f_date = \"Obs_Date\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "doyNXGqUVzag"
      },
      "outputs": [],
      "source": [
        "def getValue(text, splitID, listMarkers):\n",
        "\n",
        "  dummy = \"\"\n",
        "\n",
        "  for w in text:\n",
        "\n",
        "    if w not in listMarkers and w != splitID:\n",
        "      dummy += w + \" \"\n",
        "    else:\n",
        "      return dummy[:-1]\n",
        "\n",
        "\n",
        "  return dummy[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hZJ0xCKDVzag"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def buildDict(textFile, listIdentifiers, splitID, listMarkers):\n",
        "\n",
        "    #open the txt file\n",
        "    with open(textFile) as f:\n",
        "        lines = f.read()\n",
        "\n",
        "    # get Fund_Name\n",
        "    fund_name = lines.split('\\n')[2].split(\"Fund_Name \")[-1]\n",
        "\n",
        "    #parse the text file to build a dictionary\n",
        "    record = {}\n",
        "\n",
        "    record['fund_name'] = fund_name\n",
        "\n",
        "    #turn the text file into a list of words\n",
        "    listWords = lines.split()\n",
        "\n",
        "    #split the text into topics\n",
        "    len_text = len(listWords)\n",
        "\n",
        "\n",
        "    if re.search(splitID, lines):\n",
        "\n",
        "\n",
        "      for i in range(len_text):\n",
        "\n",
        "        if listWords[i] == listIdentifiers[0]:\n",
        "          record[listIdentifiers[0]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] == listIdentifiers[1]:\n",
        "          record[listIdentifiers[1]] = listWords[i+1]\n",
        "\n",
        "\n",
        "        if listWords[i]  == splitID:\n",
        "          record[listWords[i + 1]] = {}\n",
        "          year = listWords[i + 1]\n",
        "\n",
        "        if listWords[i] in listMarkers:\n",
        "            record[year][listWords[i]] = getValue(listWords[i+1:], splitID, listMarkers)\n",
        "\n",
        "    else:\n",
        "\n",
        "      for i in range(len_text):\n",
        "\n",
        "        if listWords[i] == listIdentifiers[0]:\n",
        "          record[listIdentifiers[0]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] == listIdentifiers[1]:\n",
        "          record[listIdentifiers[1]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] in listMarkers:\n",
        "            record[listWords[i]] = getValue(listWords[i+1:], splitID, listMarkers)\n",
        "\n",
        "\n",
        "    return record\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JN29ULNxVzah"
      },
      "outputs": [],
      "source": [
        "#dates = [i.date for index,i in enumerate(listReports) if index%2==0]\n",
        "def bm25_ranking_with_preprocessing(query, nodes_texts, top_k):\n",
        "    corpus = [preprocess_text(text) for text in nodes_texts.values()]\n",
        "    tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "    query = preprocess_text(query).split(\" \")\n",
        "    scores = bm25.get_scores(query)\n",
        "    results = tuple((score, node, text,node.tag,node.page_num) for score, (node, text) in zip(scores, nodes_texts.items()))\n",
        "    results_df = pd.DataFrame(results,columns=['score','node','text','tag','page_num'])\n",
        "    ranked_df  = results_df[results_df['score']!=0].sort_values(by='score',ascending=False).head(top_k)\n",
        "    return ranked_df\n",
        "\n",
        "\n",
        "def wanted_unwanted_funds(edgar_report,wanted_fund):\n",
        "  funds = [k[1].lower() for k in edgar_report.listFunds] # list all the funds in the report #Fidelity Dividend Growth Fund\n",
        "  wanted = [x.lower() for x in wanted_fund]\n",
        "  funds.remove(wanted[0])\n",
        "  unwanted = funds\n",
        "  return (wanted,unwanted)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ5yhRrQO_x7"
      },
      "source": [
        "## Defining Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VJNSABlXXJ_m"
      },
      "outputs": [],
      "source": [
        "# merge two consecutive nodes of type header if they are similary in text \"title\"\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_similarity(str1, str2):\n",
        "    try:\n",
        "      vectorizer = CountVectorizer(min_df=1).fit_transform([str1, str2])\n",
        "      vectors = vectorizer.toarray()\n",
        "      similarity = cosine_similarity(vectors[0].reshape(1, -1), vectors[1].reshape(1, -1))[0][0]\n",
        "      return similarity * 100\n",
        "    except:\n",
        "      return 0\n",
        "\n",
        "def merge_nodes(node):\n",
        "    if node:\n",
        "        i = 0\n",
        "        while i < len(node.children) - 1:\n",
        "            similarity = calculate_similarity(node.children[i].text, node.children[i + 1].text)\n",
        "            if similarity > 80 and not node.children[i].tag.startswith('p') and not node.children[i].tag.startswith('s'):\n",
        "                if node.children[i + 1].tag not in ['p', 's']:\n",
        "                    # Use the text of the first node and include the children of the second node\n",
        "                    node.children[i].children.extend(node.children[i + 1].children)\n",
        "                    del node.children[i + 1]\n",
        "                else:\n",
        "                    i += 1\n",
        "            else:\n",
        "                i += 1\n",
        "        for child in node.children:\n",
        "            merge_nodes(child)\n",
        "    return node  # Return the modified node\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "\n",
        "\n",
        "# nltk.download('punkt')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalpha()]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "def bm25_ranking_with_preprocessing(query, nodes_texts, top_k): # nodes_text is a dict of node:text\n",
        "    corpus = [preprocess_text(text) for text in nodes_texts.values()]\n",
        "    tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "    bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "    query = preprocess_text(query).split(\" \")\n",
        "    scores = bm25.get_scores(query)\n",
        "    results = tuple((score, node, text,node.tag, node.page_num) for score, (node, text) in zip(scores, nodes_texts.items()))\n",
        "    results_df = pd.DataFrame(results,columns=['score','node','text','tag', 'page_num'])\n",
        "    ranked_df  = results_df[results_df['score']!=0].sort_values(by='score',ascending=False).head(top_k)\n",
        "    return ranked_df\n",
        "\n",
        "def get_all_nodes_under(node):\n",
        "    nodes = [node]\n",
        "    for child in node.children:\n",
        "        nodes.extend(get_all_nodes_under(child))\n",
        "    return nodes\n",
        "\n",
        "def remove_tags_starting_with_s_or_p(df):\n",
        "    filtered_df = df[~df['tag'].str.startswith(('s', 'p'))]\n",
        "    return filtered_df\n",
        "import pandas as pd\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def filter_max_children(df):\n",
        "    max_children_rows = pd.DataFrame(columns=df.columns)\n",
        "    for score in df['score'].unique():\n",
        "        temp_df = df[df['score'] == score]\n",
        "        if len(temp_df) > 1:\n",
        "            for text in temp_df['text'].unique():\n",
        "                text_df = temp_df[temp_df['text'] == text]\n",
        "                if len(text_df) > 1:\n",
        "                    max_n_children = text_df['n_children'].max()\n",
        "                    max_children_rows = pd.concat([max_children_rows, text_df[text_df['n_children'] == max_n_children]])\n",
        "                else:\n",
        "                    max_children_rows = pd.concat([max_children_rows, text_df])\n",
        "        else:\n",
        "            max_children_rows = pd.concat([max_children_rows, temp_df])\n",
        "    return max_children_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DNp11cRU5VSq"
      },
      "outputs": [],
      "source": [
        "def tag_frequency(root_node):\n",
        "    tag_freq = {}\n",
        "\n",
        "    # Helper function to traverse the tree and count tag frequencies\n",
        "    def traverse(node):\n",
        "        if node.tag in tag_freq:\n",
        "            tag_freq[node.tag] += 1\n",
        "        else:\n",
        "            tag_freq[node.tag] = 1\n",
        "        for child in node.children:\n",
        "            traverse(child)\n",
        "\n",
        "    # Start traversing from the root node\n",
        "    traverse(root_node)\n",
        "\n",
        "    return tag_freq\n",
        "def report_to_graph(url,pdf_name,wanted=[],unwanted=[],edgar_flag=0):\n",
        "  \"\"\" if edgar flag is set, it discards wanted,unwanted parameters and use the links, discarding extraction of fundpages\"\"\"\n",
        "  if edgar_flag:\n",
        "    pdf_fundpages(url,wanted,unwanted,pdf_name) # list of wanted & unwanted funds, saves fund related pages\n",
        "  else:\n",
        "    pdf_from_url(url,pdf_name) #replaced with the remove_tables_from_html_.... line to remove tables from pdf first\n",
        "  #remove_tables_from_html_link_and_save_as_pdf(url, pdf_name)\n",
        "\n",
        "  print('done')\n",
        "  my_file = f\"{pdf_name}.pdf\"\n",
        "  doc = fitz.open(my_file)\n",
        "\n",
        "  output = []\n",
        "\n",
        "  for page in doc:\n",
        "\n",
        "      output += page.get_text(\"blocks\")\n",
        "\n",
        "  previous_block_id = 0 # Set a variable to mark the block id\n",
        "  blocks = []\n",
        "  for block in output:\n",
        "\n",
        "      if block[6] == 0: # We only take the text\n",
        "\n",
        "            #if previous_block_id != block[5]: # Compare the block number\n",
        "\n",
        "                #print(\">>>>>>>>>>>>>>>>>>>>\\n\")\n",
        "\n",
        "            plain_text = cleaning(block[4])\n",
        "            blocks.append(block)\n",
        "\n",
        "            #print(plain_text)\n",
        "  df = pd.DataFrame(blocks,columns=['x0','y0','x1','y1','text','block_no','block_type'])\n",
        "  df['text'] = df['text'].apply(lambda x:cleaning(x))\n",
        "  df = df.drop(df[df.block_type == 1 ].index)\n",
        "\n",
        "  # ===================================\n",
        "\n",
        "  block_dict = {}\n",
        "\n",
        "  page_num = 1\n",
        "\n",
        "  for page in doc: # Iterate all pages in the document\n",
        "\n",
        "        file_dict = page.get_text('dict') # Get the page dictionary\n",
        "\n",
        "        block = file_dict['blocks'] # Get the block information\n",
        "\n",
        "        block_dict[page_num] = block # Store in block dictionary\n",
        "\n",
        "        page_num += 1 # Increase the page value by 1\n",
        "\n",
        "# ============================\n",
        "  import re\n",
        "\n",
        "  spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
        "\n",
        "  rows = []\n",
        "\n",
        "  for page_num, blocks in block_dict.items():\n",
        "\n",
        "      for block in blocks:\n",
        "\n",
        "          if block['type'] == 0:\n",
        "\n",
        "              for line in block['lines']:\n",
        "\n",
        "                  for span in line['spans']:\n",
        "\n",
        "\n",
        "\n",
        "                      xmin, ymin, xmax, ymax = list(span['bbox'])\n",
        "\n",
        "                      font_size = span['size']\n",
        "\n",
        "                      text = cleaning(span['text'])\n",
        "\n",
        "                      span_font = span['font']\n",
        "\n",
        "\n",
        "\n",
        "                      is_upper = False\n",
        "\n",
        "                      is_bold = False\n",
        "\n",
        "\n",
        "\n",
        "                      if \"bold\" in span_font.lower():\n",
        "\n",
        "                          is_bold = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                      if re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text).isupper():\n",
        "\n",
        "                          is_upper = True\n",
        "\n",
        "\n",
        "\n",
        "                      if text.replace(\" \",\"\") !=  \"\":\n",
        "\n",
        "                          rows.append((xmin, ymin, xmax, ymax, text, is_upper, is_bold, span_font, font_size,page_num,block['number']))\n",
        "\n",
        "\n",
        "\n",
        "  span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text', 'is_upper','is_bold','span_font', 'font_size','page_num','block_number'])\n",
        "\n",
        "\n",
        "# ========================================\n",
        "\n",
        "  span_scores = []\n",
        "\n",
        "  span_num_occur = {}\n",
        "\n",
        "  special = '[(_:/,#%\\=@)]'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for index, span_row in span_df.iterrows():\n",
        "\n",
        "\n",
        "\n",
        "      score = round(span_row.font_size)\n",
        "\n",
        "      text = span_row.text\n",
        "\n",
        "\n",
        "\n",
        "      if not re.search(special, text):\n",
        "\n",
        "\n",
        "\n",
        "          if span_row.is_bold:\n",
        "\n",
        "              score +=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          if span_row.is_upper:\n",
        "\n",
        "              score +=1\n",
        "\n",
        "\n",
        "\n",
        "      span_scores.append(score)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  values, counts = np.unique(span_scores, return_counts=True)\n",
        "\n",
        "  #==================================\n",
        "\n",
        "\n",
        "  style_dict = {}\n",
        "\n",
        "  for value, count in zip(values, counts):\n",
        "\n",
        "      style_dict[value] = count\n",
        "\n",
        "  sorted(style_dict.items(), key=lambda x: x[1])\n",
        "\n",
        "\n",
        "  # =============================\n",
        "\n",
        "  p_size = max(style_dict, key=style_dict.get)\n",
        "  #p_size = span_df[span_df['text'].str.contains('dear', case=False)].font_size.values[0]+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  idx = 0\n",
        "\n",
        "  tag = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  for size in sorted(values, reverse = True):\n",
        "\n",
        "      idx += 1\n",
        "\n",
        "      if size == p_size:\n",
        "\n",
        "          idx = 0\n",
        "\n",
        "          tag[size] = 'p'\n",
        "\n",
        "      if size > p_size:\n",
        "\n",
        "          tag[size] = 'h{0}'.format(idx)\n",
        "\n",
        "      if size < p_size:\n",
        "\n",
        "          tag[size] = 's{0}'.format(idx)\n",
        "\n",
        "\n",
        "  # =================================\n",
        "\n",
        "  span_tags = [tag[score] for score in span_scores]\n",
        "\n",
        "  span_df['tag'] = span_tags\n",
        "\n",
        "\n",
        "\n",
        "  def split_dataframe_page_numbers(df):\n",
        "    # takes a dataframe as input and group items by page_num then block_number to be used later (in merge_procedure) to merge text items in the same block\n",
        "    # this function has drawback, that it fails in the case of small page size, since multiple small pdf pages are extracted as one page, so it combines\n",
        "    # text items in the same page and block, then merge_prcedure merge them, oversighting the fact that they come from different pdf pages\n",
        "    split_dfs = []\n",
        "    for (block_number, page_num), group in df.groupby(['page_num','block_number']): # modified, i changed it to put page_num first\n",
        "        split_dfs.append(group)\n",
        "    return split_dfs\n",
        "\n",
        "  def merge_and_append(merge, new):\n",
        "      if len(merge) > 0:\n",
        "        combined_merge = combine_text_blocks(merge)\n",
        "        result = pd.concat([combined_merge, new], ignore_index=True)\n",
        "      else:\n",
        "        result = new\n",
        "      return result\n",
        "\n",
        "  def combine_text_blocks(df):\n",
        "      tag_order = {'h0': 0, 'h1': 1, 'h2': 2, 'h3': 3, 'h4': 4, 'h5': 5,'h6':6,'h7':7,'h8':8,'h9':9,'h10':10,'h11':11, 'h12': 12,'h13':13, 'p': 14,'s':15, 's1': 16,\n",
        "                's2':17,'s3':18, 's4': 19,'s5':20, 's6': 21, 's7': 22}\n",
        "      combined_df = df.groupby(['block_number', 'page_num']).apply(lambda x: pd.Series({ # doesn't matter which is first as long as we pass rows for a same page and bock\n",
        "          'xmin': x['xmin'].iloc[0],\n",
        "          'xmax': x['xmax'].iloc[0],\n",
        "          'ymin': x['ymin'].iloc[0],\n",
        "          'ymax': x['ymax'].iloc[0],\n",
        "          'tag': x['tag'][x['tag'].map(tag_order).idxmin()], # modified 28/2/2024, we set the tag of the merged rows to be the max tag (min bec. order reversed)\n",
        "          'font_size': x['font_size'].iloc[0],\n",
        "          'is_bold': x['is_bold'].iloc[0],\n",
        "          'is_upper': x['is_upper'].iloc[0],\n",
        "          'span_font': x['span_font'].iloc[0],\n",
        "          'text': combine_text(x['text'], x['tag'], tag_order)\n",
        "      })).reset_index()\n",
        "      return combined_df.sort_values(by=['page_num', 'block_number']).reset_index(drop=True)\n",
        "\n",
        "  def combine_text(text_series, tag_series, tag_order):\n",
        "      combined_text = text_series.iloc[0]  # Initialize with the first text\n",
        "      reference_tag = tag_series.iloc[0]\n",
        "\n",
        "\n",
        "      for i in range(1, len(text_series)):\n",
        "          current_tag = tag_series.iloc[i]\n",
        "          if current_tag == reference_tag:\n",
        "              combined_text += ' ' + text_series.iloc[i]\n",
        "          else:\n",
        "              if tag_order[current_tag] > tag_order[reference_tag]:\n",
        "                  combined_text += '' + text_series.iloc[i]\n",
        "              else:\n",
        "                  combined_text += ' ' + text_series.iloc[i]\n",
        "          #reference_tag = current_tag\n",
        "      return combined_text\n",
        "\n",
        "\n",
        "  def merge_procedure(df):\n",
        "    \"\"\" takes a dataframe, combine headers until hit p,s or any long sentence \"\"\"\n",
        "    blocks_pages = split_dataframe_page_numbers(df)\n",
        "    df_combined = pd.DataFrame()\n",
        "    for block_page in blocks_pages:\n",
        "      combine = []\n",
        "      skip_combine = 0\n",
        "      new = []\n",
        "      for index,row in block_page.iterrows():\n",
        "        if len(row.text.split(\" \"))<4 and skip_combine == 0:\n",
        "          combine.append(row)\n",
        "        else:\n",
        "          new.append(row)\n",
        "          skip_combine=1\n",
        "\n",
        "      current_df = merge_and_append(pd.DataFrame(combine),pd.DataFrame(new))\n",
        "      df_combined = pd.concat([df_combined, current_df], ignore_index=True)\n",
        "    df_combined = df_combined.sort_values(by=['page_num', 'block_number']).reset_index(drop=True)\n",
        "    return df_combined\n",
        "\n",
        "  # span_df = combine_text_blocks(span_df)\n",
        "  span_df = merge_procedure(span_df)\n",
        "# ==========================================\n",
        "\n",
        "  def merge_consecutive_nodes_with_same_tag(node):\n",
        "    \"\"\"merge two consecutive nodes with the same name and tag\"\"\"\n",
        "    if node:\n",
        "        i = 0\n",
        "        while i < len(node.children) - 1:\n",
        "            if node.children[i].tag == node.children[i + 1].tag and (node.children[i].text == node.children[i + 1].text or node.children[i].text == node.children[i + 1].text):\n",
        "                # node.children[i].text += node.children[i + 1].text # this will duplicate the text/title\n",
        "                node.children[i].children.extend(node.children[i + 1].children)\n",
        "                del node.children[i + 1]\n",
        "            else:\n",
        "                i += 1\n",
        "        for child in node.children:\n",
        "            merge_consecutive_nodes_with_same_tag(child)\n",
        "    return node\n",
        "\n",
        "  # working as it returns linkedlist but it may doesn't add all nodes in the linkedlist # worked !\n",
        "  class Node:\n",
        "      def __init__(self, text, tag, page_num):\n",
        "          self.text = text\n",
        "          self.tag = tag\n",
        "          self.page_num = page_num\n",
        "          self.parent = None\n",
        "          self.children = []\n",
        "\n",
        "  # Sample data\n",
        "  # data = {\n",
        "  #     'text': ['root','ahmed', 'goes', 'to', 'by', 'foot', 'but', 'he', 'is', 'late','for','school','right'],\n",
        "  #     'tag': ['h0','h1', 'h2', 'h2', 'h3', 'p', 'h1', 's', 'h3', 'h2','p','h4','h5']\n",
        "  # }\n",
        "  x=span_df['text'].tolist()\n",
        "  x.insert(0,'root')\n",
        "  y=span_df['tag'].tolist()\n",
        "  y.insert(0,'h0') # insert tag h0 at index '0' for the root node to be the parent of all the nodes in the tree\n",
        "  z=span_df['page_num'].tolist()\n",
        "  z.insert(0,1) # at position 0 which is the root, assign page_num of value page_num=1\n",
        "\n",
        "\n",
        "  data ={\n",
        "\n",
        "      \"text\": x,\n",
        "      \"tag\" : y,\n",
        "      'page_num' : z\n",
        "  }\n",
        "\n",
        "  # Define the tag order dictionary\n",
        "  tag_order = {'h0': 0, 'h1': 1, 'h2': 2, 'h3': 3, 'h4': 4, 'h5': 5,'h6':6,'h7':7,'h8':8,'h9':9,'h10':10,'h11':11, 'h12': 12,'h13':13, 'p': 14,'s':15, 's1': 16,\n",
        "              's2':17,'s3':18, 's4': 19,'s5':20, 's6': 21, 's7': 22}\n",
        "\n",
        "  # Create nodes for each data point\n",
        "  nodes = [Node(text, tag, page_num) for (text, tag,page_num) in zip(data['text'], data['tag'], data['page_num'])]\n",
        "\n",
        "  # Build the linked list\n",
        "  for i in range(1, len(nodes)):\n",
        "      current_node = nodes[i]\n",
        "      parent = None\n",
        "      for j in range(i - 1, -1, -1):\n",
        "          if tag_order[nodes[j].tag] < tag_order[current_node.tag]:\n",
        "              parent = nodes[j]\n",
        "              break\n",
        "      if parent:\n",
        "          current_node.parent = parent\n",
        "          parent.children.append(current_node)\n",
        "      else:\n",
        "          for j in range(i - 1, -1, -1):\n",
        "              if tag_order[nodes[j].tag] > tag_order[current_node.tag]:\n",
        "                  current_node.parent = nodes[j].parent\n",
        "                  nodes[j].parent = current_node\n",
        "                  current_node.children.append(nodes[j])\n",
        "                  break\n",
        "\n",
        "  # Find the root node\n",
        "  root = nodes[0]\n",
        "  while root.parent:\n",
        "      root = root.parent\n",
        "\n",
        "\n",
        "  root = merge_consecutive_nodes_with_same_tag(root)\n",
        "  frequency_of_tags = tag_frequency(root)\n",
        "\n",
        "  # Call the function on the root node to start the merging process\n",
        "  #modified_root = merge_nodes(root)\n",
        "\n",
        "  #return span_df,frequency_of_tags,modified_root\n",
        "  return span_df,frequency_of_tags,root"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "cacw6Cz2MhDO"
      },
      "outputs": [],
      "source": [
        "def get_all_nodes_except_p_s(root):\n",
        "    result = []\n",
        "\n",
        "    def dfs(node):\n",
        "        if not node.text.startswith('p') and not node.text.startswith('s'):\n",
        "            result.append(node)\n",
        "        for child in node.children:\n",
        "            dfs(child)\n",
        "\n",
        "    dfs(root)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def increase_page_num_on_decreasing_block_num(df):\n",
        "    # Group by 'page_num'\n",
        "    grouped_df = df.groupby('page_num')\n",
        "\n",
        "    # Initialize an empty DataFrame to store the modified rows\n",
        "    modified_rows = pd.DataFrame()\n",
        "\n",
        "    # Iterate through each group\n",
        "    for page_num, group in grouped_df:\n",
        "        # Check for decreasing 'block_num'\n",
        "        decreasing_block_num = group['block_num'].diff() < 0\n",
        "\n",
        "        # If any row has decreasing 'block_num', increase 'page_num' for the rows underneath\n",
        "        if decreasing_block_num.any():\n",
        "            # Identify the indices where 'block_num' is decreasing\n",
        "            indices_to_increase = group[decreasing_block_num].index\n",
        "\n",
        "            # Increase 'page_num' for the rows underneath\n",
        "            for idx in indices_to_increase:\n",
        "              df.loc[idx:, 'page_num'] += 1\n",
        "\n",
        "            # Append the modified rows to the DataFrame\n",
        "            modified_rows = modified_rows.append(df.loc[indices_to_increase])\n",
        "\n",
        "    return modified_rows\n",
        "\n",
        "# Example usage\n",
        "data = {'block_num': [1, 2, 1, 1, 2, 1, 2, 3, 1, 1],\n",
        "        'page_num': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "\n",
        "# modified_rows = increase_page_num_on_decreasing_block_num(df)\n",
        "# print(\"\\nModified DataFrame:\")\n",
        "# print(df)\n",
        "# print(\"\\nModified Rows:\")\n",
        "# print(modified_rows)\n"
      ],
      "metadata": {
        "id": "n6EnbnjWxwVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CegdAZm3xwfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN6tXfxd_YJ"
      },
      "source": [
        "## Automate multiple annotation files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ImLUJQv19g85"
      },
      "outputs": [],
      "source": [
        "#list of markers and identifiers (structure of text file is known beforehad)\n",
        "markers =  [\"Reporting_Date\",\n",
        "            \"Table_Contents\",\n",
        "            \"Letter_CEO\",\n",
        "            \"Letter_CEO_Title\",\n",
        "            \"Letter_SM\",\n",
        "            \"Letter_SM_Title\",\n",
        "            \"Letter_GEC\",\n",
        "            \"Letter_MDFP\",\n",
        "            \"GEC\",\n",
        "            \"GEC_Title\",\n",
        "            \"MDFP\",\n",
        "            \"MDFP_Title\",\n",
        "            \"MDFP_GEC\",\n",
        "            \"Comments_RA\"]\n",
        "\n",
        "identifiers = [\"Line_Number\", \"Series\"]\n",
        "\n",
        "f_date = \"Reporting_Date\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9QsMSpFd9g86"
      },
      "outputs": [],
      "source": [
        "def getValue(text, splitID, listMarkers):\n",
        "\n",
        "  dummy = \"\"\n",
        "\n",
        "  for w in text:\n",
        "\n",
        "    if w not in listMarkers and w != splitID:\n",
        "      dummy += w + \" \"\n",
        "    else:\n",
        "      return dummy[:-1]\n",
        "\n",
        "\n",
        "  return dummy[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HGDfQowv9g86"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def buildDict(textFile, listIdentifiers, splitID, listMarkers):\n",
        "\n",
        "    #open the txt file\n",
        "    with open(textFile) as f:\n",
        "        lines = f.read()\n",
        "\n",
        "    #parse the text file to build a dictionary\n",
        "    record = {}\n",
        "\n",
        "\n",
        "\n",
        "    #turn the text file into a list of words\n",
        "    listWords = lines.split()\n",
        "\n",
        "    #split the text into topics\n",
        "    len_text = len(listWords)\n",
        "\n",
        "    flag_series = 0\n",
        "    if re.search(splitID, lines):\n",
        "\n",
        "\n",
        "      for i in range(len_text):\n",
        "\n",
        "        if listWords[i] == listIdentifiers[0]:\n",
        "          record[listIdentifiers[0]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] == listIdentifiers[1] and flag_series == 0:\n",
        "          flag_series=1\n",
        "          record[listIdentifiers[1]] = listWords[i+1]\n",
        "\n",
        "\n",
        "        if listWords[i]  == splitID:\n",
        "          record[listWords[i + 1]] = {}\n",
        "          year = listWords[i + 1]\n",
        "\n",
        "        if listWords[i] in listMarkers:\n",
        "            record[year][listWords[i]] = getValue(listWords[i+1:], splitID, listMarkers)\n",
        "\n",
        "    else:\n",
        "\n",
        "      for i in range(len_text):\n",
        "\n",
        "        if listWords[i] == listIdentifiers[0]:\n",
        "          record[listIdentifiers[0]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] == listIdentifiers[1] and flag_series == 0:\n",
        "          flag_series = 1\n",
        "          record[listIdentifiers[1]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] in listMarkers:\n",
        "            record[listWords[i]] = getValue(listWords[i+1:], splitID, listMarkers)\n",
        "\n",
        "\n",
        "    # get Fund_Name\n",
        "    return record\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqDVv3Ryjrnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pCZqHZOk44Z"
      },
      "outputs": [],
      "source": [
        "# loop through annotation files\n",
        "from google.colab import files\n",
        "from glob import glob\n",
        "import time\n",
        "\n",
        "\n",
        "textual_dict = {}         # this is for saving textual elements df of different files, it uses text_dict_dates dictionary\n",
        "one_sample_setting = 1\n",
        "MDFP_Title = 1\n",
        "if one_sample_setting:\n",
        "  print(\"One_Sample_Setting\")\n",
        "if MDFP_Title:\n",
        "  print(\"MDFP titles included only\")\n",
        "\n",
        "total_df = pd.DataFrame(columns = [\"date\", \"truth\",'extracted','tree'])\n",
        "\n",
        "extracted_files = glob('*.txt')\n",
        "for index,file in enumerate(extracted_files):\n",
        "  # ==============\n",
        "  print(index+1,' ======== ',file)\n",
        "  records = buildDict(file,identifiers,f_date,markers)\n",
        "\n",
        "\n",
        "  # ==============\n",
        "  one_year_fund = 0\n",
        "  multi_year_fund = 0\n",
        "  try: # to handle any missing field or different strucutre\n",
        "    ann_date_mdfp = {}\n",
        "    for index,(k,v) in enumerate(records.items()):\n",
        "      if index > 2:\n",
        "        if 'MDFP' in v:\n",
        "          ann_date_mdfp[k] = v['MDFP']\n",
        "          multi_year_fund+=1\n",
        "        elif 'MDFP' in records:\n",
        "          ann_date_mdfp[k] = records['MDFP']\n",
        "          one_year_fund+=1\n",
        "  except Exception as ex:\n",
        "    print(\"Missing file or Different structure txt file\")\n",
        "    continue\n",
        "\n",
        "  ann = pd.DataFrame(ann_date_mdfp.items(),columns = [\"date\", \"truth\"])\n",
        "  ann['extracted'] = ''\n",
        "\n",
        "  ann = ann[ann.truth!='NA']\n",
        "  ann['year'] = ann.date.apply(lambda x:x.split('-')[0])\n",
        "  ann = ann.groupby('year').first().reset_index()\n",
        "  ann['file'] = file\n",
        "\n",
        "  try:\n",
        "    sn = records['Series']\n",
        "    if MDFP_Title:   # if specified, then select only years where MDFP section has title\n",
        "      x = pd.DataFrame(records).transpose().drop(['Series','Line_Number'],axis=0)\n",
        "      x = x[x.MDFP_Title!='NA']\n",
        "      records = x.transpose().to_dict()\n",
        "    # sn = records['Series']\n",
        "    listReports = searchEdgarNCSR(sn, 100)\n",
        "    listReports = [i for i in listReports if i.filing=='N-CSR']\n",
        "\n",
        "    wanted_fund = [listReports[0].name]\n",
        "    dates = []\n",
        "    wanted = []\n",
        "    unwanted = []\n",
        "    links = []\n",
        "    for i in range(len(listReports)):\n",
        "      try:\n",
        "        w,u = wanted_unwanted_funds(listReports[i],wanted_fund)\n",
        "        dates.append(listReports[i].reportingDate)\n",
        "        links.append(listReports[i].link)\n",
        "        wanted.append(w)\n",
        "        unwanted.append(u)\n",
        "      except Exception as e: # fund doesn't exist in this year\n",
        "        print(e)\n",
        "        print(f\"Can't find wanted fund in {listReports[i].reportingDate}\")\n",
        "\n",
        "\n",
        "    #edgar_df = pd.DataFrame(np.column_stack([dates,links,wanted,unwanted]),columns=['date','link','wanted','unwanted'])\n",
        "    edgar_df = pd.DataFrame({'date':dates,'link':links,'wanted':wanted,'unwanted':unwanted, 'tree':'NA'})\n",
        "    edgar_df.date = pd.to_datetime(edgar_df.date).apply(lambda x: x.strftime('%Y-%m-%d')) # make it standard date to facilitate the merge\n",
        "    ann.date = pd.to_datetime(ann.date).apply(lambda x: x.strftime('%Y-%m-%d'))           # make it standard date to facilitate the merge\n",
        "    edgar_df = edgar_df.merge(ann,on='date',how='inner') # inner join \"merge\" on date column\n",
        "    text_dict_dates = {}      # this is for saving textual elements dataframe of specific file, and initialize every new file\n",
        "\n",
        "\n",
        "    if one_sample_setting:                            # if specified, then use the most recent year only\n",
        "      edgar_df = edgar_df[edgar_df.year == ann.year.values.max()] # to set only the latest year according to ann last 'annotation' year\n",
        "\n",
        "\n",
        "\n",
        "    results = []\n",
        "    for index,row in edgar_df.iterrows():\n",
        "      try:\n",
        "        # df,style,root = report_to_graph(url,f\"{url.replace('/','$')}_{index}\",wanted,unwanted)\n",
        "        df,style,root = report_to_graph(row.link,f'{row.wanted[0]}_{row.date.split(\"-\")[0]}',row.wanted,row.unwanted,1)\n",
        "        # df, style, root = report_to_graph(url,f\"{url.replace('/','$')}_{index}\") # report_to_graph function is defined bellow\n",
        "        results.append([row.date,df,style,root])\n",
        "        text_dict_dates[row.date] = df # add textual dataframe\n",
        "      except Exception as e:\n",
        "        print(f\" ============= Error encountered ======== {e}\")\n",
        "\n",
        "\n",
        "    # add automatic extraction to the dataframe \"edgar_df\" containing date, true MDFP for easy comparison\n",
        "    for i,report in enumerate(results):\n",
        "\n",
        "      all_nodes = get_all_nodes_except_p_s(report[2+1]) # bec. we added date at first index\n",
        "      all_nodes  = {node:node.text for node in all_nodes}\n",
        "\n",
        "      query = \"fund performance discussion commentary\"\n",
        "      #query = \"fund portfolio commentary management performance discussion\"\n",
        "      top_k = 100\n",
        "      ranking = bm25_ranking_with_preprocessing(query, all_nodes, top_k)\n",
        "      ranking['n_children']=ranking.node.apply(lambda x:len(x.children))\n",
        "      filtered_ranking = ranking[ranking['n_children']>0] # filter out matches with no children\n",
        "      # filtered_ranking = filter_max_children(filtered_ranking)\n",
        "\n",
        "      filtered_ranking = remove_tags_starting_with_s_or_p(filtered_ranking)\n",
        "      max_rank = filtered_ranking.score.max()\n",
        "      max_ranking_df = filtered_ranking[filtered_ranking.score == max_rank]\n",
        "      max_ranking_df = select_two_pages(max_ranking_df)\n",
        "      text = ''\n",
        "      for index,row in max_ranking_df.iterrows():\n",
        "          text += '\\n'.join([node.text for node in get_all_nodes_under(row.node)[1:]])\n",
        "          text+='\\n\\n'\n",
        "\n",
        "      print(links[i])\n",
        "      print(edgar_df.date.values[i])\n",
        "      edgar_df['extracted'][edgar_df.date == report[0]] = text\n",
        "      edgar_df['tree'][edgar_df.date == report[0]] = report[2+1] # add the root node in the dataframe\n",
        "\n",
        "\n",
        "\n",
        "      print(\"==============================\")\n",
        "    textual_dict[file] =  text_dict_dates\n",
        "    total_df = pd.concat([total_df,edgar_df])\n",
        "\n",
        "    print(f\" =============== Finished file : {file} =================\")\n",
        "  except Exception as e:\n",
        "    # print(e)\n",
        "    print(\"couldn't retrive from edgar database\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9XgDhzq206k",
        "outputId": "7d851102-1d93-45e6-e548-a6021ea76cc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# filter the empty extracted\n",
        "empty_df = total_df[total_df.extracted==''] # save empty extracted in new dataframe\n",
        "total_df = total_df[total_df.extracted!=''] # remove empty extracted\n",
        "total_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn0MseY3ysOL",
        "outputId": "0da02f9f-4d32-43e2-87e9-de3b71b07337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# total_df.to_csv('data.csv')\n",
        "total_df = pd.read_csv(\"data.csv\")\n",
        "total_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2e0-AWu91sO",
        "outputId": "71e50753-01d4-4721-9f7f-4d9d27431618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(162, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1\n",
        "Fix the year and run on all the reports"
      ],
      "metadata": {
        "id": "WFZKP6hCpYSA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPzV5xTWymXh"
      },
      "outputs": [],
      "source": [
        "#list of markers and identifiers (structure of text file is known beforehad)\n",
        "markers =  [\"Reporting_Date\",\n",
        "            \"Table_Contents\",\n",
        "            \"Letter_CEO\",\n",
        "            \"Letter_CEO_Title\",\n",
        "            \"Letter_SM\",\n",
        "            \"Letter_SM_Title\",\n",
        "            \"Letter_GEC\",\n",
        "            \"Letter_MDFP\",\n",
        "            \"GEC\",\n",
        "            \"GEC_Title\",\n",
        "            \"MDFP\",\n",
        "            \"MDFP_Title\",\n",
        "            \"MDFP_GEC\",\n",
        "            \"Comments_RA\"]\n",
        "\n",
        "identifiers = [\"Line_Number\", \"Series\"]\n",
        "\n",
        "f_date = \"Reporting_Date\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-iWXR27ymXs"
      },
      "outputs": [],
      "source": [
        "def getValue(text, splitID, listMarkers):\n",
        "\n",
        "  dummy = \"\"\n",
        "\n",
        "  for w in text:\n",
        "\n",
        "    if w not in listMarkers and w != splitID:\n",
        "      dummy += w + \" \"\n",
        "    else:\n",
        "      return dummy[:-1]\n",
        "\n",
        "\n",
        "  return dummy[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hc4WSbiIymXt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def buildDict(textFile, listIdentifiers, splitID, listMarkers):\n",
        "\n",
        "    #open the txt file\n",
        "    with open(textFile) as f:\n",
        "        lines = f.read()\n",
        "\n",
        "    #parse the text file to build a dictionary\n",
        "    record = {}\n",
        "\n",
        "\n",
        "\n",
        "    #turn the text file into a list of words\n",
        "    listWords = lines.split()\n",
        "\n",
        "    #split the text into topics\n",
        "    len_text = len(listWords)\n",
        "\n",
        "    flag_series = 0\n",
        "    if re.search(splitID, lines):\n",
        "\n",
        "\n",
        "      for i in range(len_text):\n",
        "\n",
        "        if listWords[i] == listIdentifiers[0]:\n",
        "          record[listIdentifiers[0]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] == listIdentifiers[1] and flag_series == 0:\n",
        "          flag_series=1\n",
        "          record[listIdentifiers[1]] = listWords[i+1]\n",
        "\n",
        "\n",
        "        if listWords[i]  == splitID:\n",
        "          record[listWords[i + 1]] = {}\n",
        "          year = listWords[i + 1]\n",
        "\n",
        "        if listWords[i] in listMarkers:\n",
        "            record[year][listWords[i]] = getValue(listWords[i+1:], splitID, listMarkers)\n",
        "\n",
        "    else:\n",
        "\n",
        "      for i in range(len_text):\n",
        "\n",
        "        if listWords[i] == listIdentifiers[0]:\n",
        "          record[listIdentifiers[0]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] == listIdentifiers[1] and flag_series == 0:\n",
        "          flag_series = 1\n",
        "          record[listIdentifiers[1]] = listWords[i+1]\n",
        "\n",
        "        if listWords[i] in listMarkers:\n",
        "            record[listWords[i]] = getValue(listWords[i+1:], splitID, listMarkers)\n",
        "\n",
        "\n",
        "    # get Fund_Name\n",
        "    return record\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through annotation files\n",
        "from google.colab import files\n",
        "from glob import glob\n",
        "import time\n",
        "\n",
        "\n",
        "textual_dict = {}         # this is for saving textual elements df of different files, it uses text_dict_dates dictionary\n",
        "one_sample_setting = 0\n",
        "MDFP_Title = 0\n",
        "year = '2018'\n",
        "missing_funds = []         # list to store funds not found in a specific year or the name is different. [(missing_funds, year)]\n",
        "structure_failure = []     # list to store files that w fail to automatically read bec. of old structure(peu-etre)\n",
        "db_issue = []              # list to store files that includes funds we can't retrieve from edgar DB\n",
        "if one_sample_setting:\n",
        "  print(\"One_Sample_Setting\")\n",
        "if MDFP_Title:\n",
        "  print(\"MDFP titles included only\")\n",
        "\n",
        "total_df = pd.DataFrame(columns = [\"date\", \"truth\",'extracted','tree'])\n",
        "\n",
        "extracted_files = glob('*.txt')\n",
        "for index,file in enumerate(extracted_files):\n",
        "  # ==============\n",
        "  print(index+1,' ======== ',file)\n",
        "  records = buildDict(file,identifiers,f_date,markers)\n",
        "\n",
        "\n",
        "  # ==============\n",
        "  one_year_fund = 0\n",
        "  multi_year_fund = 0\n",
        "  try: # to handle any missing field or different strucutre\n",
        "    ann_date_mdfp = {}\n",
        "    for index,(k,v) in enumerate(records.items()):\n",
        "      if index > 2:\n",
        "        if 'MDFP' in v:\n",
        "          ann_date_mdfp[k] = v['MDFP']\n",
        "          multi_year_fund+=1\n",
        "        elif 'MDFP' in records:\n",
        "          ann_date_mdfp[k] = records['MDFP']\n",
        "          one_year_fund+=1\n",
        "  except Exception as ex:\n",
        "    print(\"Missing file or Different structure txt file\")\n",
        "    continue\n",
        "\n",
        "  ann = pd.DataFrame(ann_date_mdfp.items(),columns = [\"date\", \"truth\"])\n",
        "  ann['extracted'] = ''\n",
        "\n",
        "  ann = ann[ann.truth!='NA']\n",
        "  ann['year'] = ann.date.apply(lambda x:x.split('-')[0])\n",
        "  ann = ann.groupby('year').first().reset_index()\n",
        "  ann['file'] = file\n",
        "\n",
        "  try:\n",
        "    sn = records['Series']\n",
        "    if MDFP_Title:   # if specified, then select only years where MDFP section has title\n",
        "      x = pd.DataFrame(records).transpose().drop(['Series','Line_Number'],axis=0)\n",
        "      x = x[x.MDFP_Title!='NA']\n",
        "      records = x.transpose().to_dict()\n",
        "    # sn = records['Series']\n",
        "    listReports = searchEdgarNCSR(sn, 100)\n",
        "    listReports = [i for i in listReports if i.filing=='N-CSR']\n",
        "\n",
        "    wanted_fund = [listReports[0].name]\n",
        "    dates = []\n",
        "    wanted = []\n",
        "    unwanted = []\n",
        "    links = []\n",
        "    for i in range(len(listReports)):\n",
        "      try:\n",
        "        w,u = wanted_unwanted_funds(listReports[i],wanted_fund)\n",
        "        dates.append(listReports[i].reportingDate)\n",
        "        links.append(listReports[i].link)\n",
        "        wanted.append(w)\n",
        "        unwanted.append(u)\n",
        "      except Exception as e: # fund doesn't exist in this year\n",
        "        print(e)\n",
        "        print(f\"Can't find wanted fund in {listReports[i].reportingDate}\")\n",
        "        missing_funds.append((w[0],listReports[i].reportingDate))\n",
        "\n",
        "\n",
        "    #edgar_df = pd.DataFrame(np.column_stack([dates,links,wanted,unwanted]),columns=['date','link','wanted','unwanted'])\n",
        "    edgar_df = pd.DataFrame({'date':dates,'link':links,'wanted':wanted,'unwanted':unwanted, 'tree':'NA'})\n",
        "    edgar_df.date = pd.to_datetime(edgar_df.date).apply(lambda x: x.strftime('%Y-%m-%d')) # make it standard date to facilitate the merge\n",
        "    ann.date = pd.to_datetime(ann.date).apply(lambda x: x.strftime('%Y-%m-%d'))           # make it standard date to facilitate the merge\n",
        "    edgar_df = edgar_df.merge(ann,on='date',how='inner') # inner join \"merge\" on date column\n",
        "    # ============= experiment 1: choose a year and fix ===============\n",
        "    edgar_df = edgar_df[edgar_df.date.str.split('-').apply(lambda x:x[0]) == year]\n",
        "    if len(edgar_df)>0:\n",
        "      print(f\"year {year} found ...\")\n",
        "    else:\n",
        "      print(f\"year {year} not found ..!\")\n",
        "    #==================================================================\n",
        "    text_dict_dates = {}      # this is for saving textual elements dataframe of specific file, and initialize every new file\n",
        "\n",
        "\n",
        "    if one_sample_setting:                            # if specified, then use the most recent year only\n",
        "      edgar_df = edgar_df[edgar_df.year == ann.year.values.max()] # to set only the latest year according to ann last 'annotation' year\n",
        "\n",
        "\n",
        "\n",
        "    results = []\n",
        "    for index,row in edgar_df.iterrows():\n",
        "      try:\n",
        "        # df,style,root = report_to_graph(url,f\"{url.replace('/','$')}_{index}\",wanted,unwanted)\n",
        "        df,style,root = report_to_graph(row.link,f'{row.wanted[0]}_{row.date.split(\"-\")[0]}',row.wanted,row.unwanted,1)\n",
        "        # df, style, root = report_to_graph(url,f\"{url.replace('/','$')}_{index}\") # report_to_graph function is defined bellow\n",
        "        results.append([row.date,df,style,root])\n",
        "        text_dict_dates[row.date] = df # add textual dataframe\n",
        "      except Exception as e:\n",
        "        print(f\" ============= Error encountered ======== {e}\")\n",
        "\n",
        "\n",
        "    # add automatic extraction to the dataframe \"edgar_df\" containing date, true MDFP for easy comparison\n",
        "    for i,report in enumerate(results):\n",
        "\n",
        "      all_nodes = get_all_nodes_except_p_s(report[2+1]) # bec. we added date at first index\n",
        "      all_nodes  = {node:node.text for node in all_nodes}\n",
        "\n",
        "      query = \"fund performance discussion commentary\"\n",
        "      #query = \"fund portfolio commentary management performance discussion\"\n",
        "      top_k = 100\n",
        "      ranking = bm25_ranking_with_preprocessing(query, all_nodes, top_k)\n",
        "      ranking['n_children']=ranking.node.apply(lambda x:len(x.children))\n",
        "      filtered_ranking = ranking[ranking['n_children']>0] # filter out matches with no children\n",
        "      # filtered_ranking = filter_max_children(filtered_ranking)\n",
        "\n",
        "      filtered_ranking = remove_tags_starting_with_s_or_p(filtered_ranking)\n",
        "      max_rank = filtered_ranking.score.max()\n",
        "      max_ranking_df = filtered_ranking[filtered_ranking.score == max_rank]\n",
        "      max_ranking_df = select_two_pages(max_ranking_df)\n",
        "      text = ''\n",
        "      for index,row in max_ranking_df.iterrows():\n",
        "          text += '\\n'.join([node.text for node in get_all_nodes_under(row.node)[1:]])\n",
        "          text+='\\n\\n'\n",
        "\n",
        "      print(links[i])\n",
        "      print(edgar_df.date.values[i])\n",
        "      edgar_df['extracted'][edgar_df.date == report[0]] = text\n",
        "      edgar_df['tree'][edgar_df.date == report[0]] = report[2+1] # add the root node in the dataframe\n",
        "\n",
        "\n",
        "\n",
        "      print(\"==============================\")\n",
        "    textual_dict[file] =  text_dict_dates\n",
        "    total_df = pd.concat([total_df,edgar_df])\n",
        "\n",
        "    print(f\" =============== Finished file : {file} =================\")\n",
        "  except Exception as e:\n",
        "    # print(e)\n",
        "    db_issue.append(file)\n",
        "    print(\"couldn't retrive from edgar database\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m71dU9XxpXX5",
        "outputId": "7e6a398e-1a73-4631-f1a2-0c9fd1626a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  ========  P644.txt\n",
            "couldn't retrive from edgar database\n",
            "2  ========  P1099.txt\n",
            "couldn't retrive from edgar database\n",
            "3  ========  P624.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "couldn't retrive from edgar database\n",
            "4  ========  P10.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "year 2018 found ...\n",
            "Selected pages saved to amcap fund_2018.pdf\n",
            "PDF created successfully: amcap fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/4405/000005193123000426/amcap_ncsr.htm\n",
            "2018-02-28\n",
            "==============================\n",
            " =============== Finished file : P10.txt =================\n",
            "5  ========  P73.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity value discovery fund_2018.pdf\n",
            "PDF created successfully: fidelity value discovery fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/81205/000008120523000061/filing7028.htm\n",
            "2018-07-31\n",
            "==============================\n",
            " =============== Finished file : P73.txt =================\n",
            "6  ========  P272.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P272.txt =================\n",
            "7  ========  P5.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-10-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P5.txt =================\n",
            "8  ========  P291.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to delaware select growth fund_2018.pdf\n",
            "PDF created successfully: delaware select growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/763749/000120677424000010/mimsgf4273261-ncsr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P291.txt =================\n",
            "9  ========  P420.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "couldn't retrive from edgar database\n",
            "10  ========  P300.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P300.txt =================\n",
            "11  ========  P18.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to delaware value fund_2018.pdf\n",
            "PDF created successfully: delaware value fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/27574/000120677424000072/mimgefii4281071-ncsr.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P18.txt =================\n",
            "12  ========  P647.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "couldn't retrive from edgar database\n",
            "13  ========  P612.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "14  ========  P729.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P729.txt =================\n",
            "15  ========  P206.txt\n",
            "couldn't retrive from edgar database\n",
            "16  ========  P103.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-06-30\n",
            "year 2018 found ...\n",
            "Selected pages saved to gold and precious metals fund_2018.pdf\n",
            "PDF created successfully: gold and precious metals fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/101507/000143510924000085/primary-document.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P103.txt =================\n",
            "17  ========  P753.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-07-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-07-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-07-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-07-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-07-31\n",
            "year 2018 found ...\n",
            "Unable to create PDF from webpage. Error: Command failed: /usr/bin/wkhtmltopdf --quiet https://www.sec.gov/Archives/edgar/data/930007/000110465918061023/a18-18658_1ncsr.htm pace small/medium co value equity investments_2018.pdf\n",
            "Check whhtmltopdf output without 'quiet' option\n",
            "[Errno 2] No such file or directory: 'pace small/medium co value equity investments_2018.pdf' \n",
            "done\n",
            " ============= Error encountered ======== no such file: 'pace small/medium co value equity investments_2018.pdf'\n",
            " =============== Finished file : P753.txt =================\n",
            "18  ========  P116.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P116.txt =================\n",
            "19  ========  P114.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to davis appreciation & income fund_2018.pdf\n",
            "PDF created successfully: davis appreciation & income fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/203002/000020300224000002/edgar.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P114.txt =================\n",
            "20  ========  P208.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-11-30\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity growth strategies fund_2018.pdf\n",
            "PDF created successfully: fidelity growth strategies fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/707823/000070782324000033/filing7222.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P208.txt =================\n",
            "21  ========  P177.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "couldn't retrive from edgar database\n",
            "22  ========  P29.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-06-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P29.txt =================\n",
            "23  ========  P680.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to value fund_2018.pdf\n",
            "PDF created successfully: value fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/908186/000090818623000021/accp33123n-csr.htm\n",
            "2018-03-31\n",
            "==============================\n",
            " =============== Finished file : P680.txt =================\n",
            "24  ========  P288.txt\n",
            "couldn't retrive from edgar database\n",
            "25  ========  P37.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-01-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-01-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-01-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-01-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-01-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P37.txt =================\n",
            "26  ========  P112.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to davis opportunity fund_2018.pdf\n",
            "PDF created successfully: davis opportunity fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/203002/000020300224000002/edgar.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P112.txt =================\n",
            "27  ========  P93.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P93.txt =================\n",
            "28  ========  P161.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "couldn't retrive from edgar database\n",
            "29  ========  P676.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to schwab core equity fund_2018.pdf\n",
            "PDF created successfully: schwab core equity fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/904333/000119312524000546/d425954dncsr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P676.txt =================\n",
            "30  ========  P210.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity independence fund_2018.pdf\n",
            "PDF created successfully: fidelity independence fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/708191/000137949121000151/filing830.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P210.txt =================\n",
            "31  ========  P214.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to royce pennsylvania mutual fund_2018.pdf\n",
            "PDF created successfully: royce pennsylvania mutual fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/709364/000094937724000010/e98512_trf-ncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P214.txt =================\n",
            "32  ========  P299.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to midas fund_2018.pdf\n",
            "PDF created successfully: midas fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/770200/000077020024000005/mst_ncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P299.txt =================\n",
            "33  ========  P287.txt\n",
            "couldn't retrive from edgar database\n",
            "34  ========  P688.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2022-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-05-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P688.txt =================\n",
            "35  ========  P406.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P406.txt =================\n",
            "36  ========  P254.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P254.txt =================\n",
            "37  ========  P429.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P429.txt =================\n",
            "38  ========  P627.txt\n",
            "couldn't retrive from edgar database\n",
            "39  ========  P283.txt\n",
            "couldn't retrive from edgar database\n",
            "40  ========  P697.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to t. rowe price communications & technology fund_2018.pdf\n",
            "PDF created successfully: t. rowe price communications & technology fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/910671/000119312524042352/d747199dncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P697.txt =================\n",
            "41  ========  P705.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P705.txt =================\n",
            "42  ========  P733.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P733.txt =================\n",
            "43  ========  P262.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-05-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P262.txt =================\n",
            "44  ========  P202.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-07-31\n",
            "couldn't retrive from edgar database\n",
            "45  ========  P245.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity advisor series small cap fund_2018.pdf\n",
            "PDF created successfully: fidelity advisor series small cap fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/722574/000072257424000054/filing7223.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P245.txt =================\n",
            "46  ========  P702.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to franklin real estate securities fund_2018.pdf\n",
            "PDF created successfully: franklin real estate securities fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/912291/000186842023000105/primary-document.htm\n",
            "2018-04-30\n",
            "==============================\n",
            " =============== Finished file : P702.txt =================\n",
            "47  ========  P614.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "48  ========  P630.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "couldn't retrive from edgar database\n",
            "49  ========  P119.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-03-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P119.txt =================\n",
            "50  ========  P170.txt\n",
            "couldn't retrive from edgar database\n",
            "51  ========  P366.txt\n",
            "couldn't retrive from edgar database\n",
            "52  ========  P176.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "couldn't retrive from edgar database\n",
            "53  ========  P722.txt\n",
            "couldn't retrive from edgar database\n",
            "54  ========  P174.txt\n",
            "couldn't retrive from edgar database\n",
            "55  ========  P297.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P297.txt =================\n",
            "56  ========  P671.txt\n",
            "couldn't retrive from edgar database\n",
            "57  ========  P609.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "couldn't retrive from edgar database\n",
            "58  ========  P699.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P699.txt =================\n",
            "59  ========  P158.txt\n",
            "couldn't retrive from edgar database\n",
            "60  ========  P444.txt\n",
            "couldn't retrive from edgar database\n",
            "61  ========  P628.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P628.txt =================\n",
            "62  ========  P169.txt\n",
            "couldn't retrive from edgar database\n",
            "63  ========  P164.txt\n",
            "couldn't retrive from edgar database\n",
            "64  ========  P698.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-11-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P698.txt =================\n",
            "65  ========  P4.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-10-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P4.txt =================\n",
            "66  ========  P66.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P66.txt =================\n",
            "67  ========  P110.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to invesco small cap growth fund_2018.pdf\n",
            "PDF created successfully: invesco small cap growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/202032/000119312524051992/d240248dncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P110.txt =================\n",
            "68  ========  P166.txt\n",
            "couldn't retrive from edgar database\n",
            "69  ========  P32.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-03-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P32.txt =================\n",
            "70  ========  P74.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P74.txt =================\n",
            "71  ========  P294.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to jpmorgan small cap value fund_2018.pdf\n",
            "PDF created successfully: jpmorgan small cap value fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/763852/000119312523227041/d507370dncsr.htm\n",
            "2018-06-30\n",
            "==============================\n",
            " =============== Finished file : P294.txt =================\n",
            "72  ========  P109.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to vanguard windsor ii fund_2018.pdf\n",
            "PDF created successfully: vanguard windsor ii fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/107606/000110465923129658/tm2331781d1_ncsr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P109.txt =================\n",
            "73  ========  P203.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to conservative allocation fund_2018.pdf\n",
            "PDF created successfully: conservative allocation fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/702435/000139834424005695/fp0086720-2_ncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P203.txt =================\n",
            "74  ========  P430.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P430.txt =================\n",
            "75  ========  P616.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "76  ========  P618.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "couldn't retrive from edgar database\n",
            "77  ========  P750.txt\n",
            "year 2018 found ...\n",
            "No valid page numbers specified.\n",
            "PDF created successfully: the growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/926243/000119312523303968/d569962dncsr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P750.txt =================\n",
            "78  ========  P172.txt\n",
            "couldn't retrive from edgar database\n",
            "79  ========  P665.txt\n",
            "year 2018 found ...\n",
            "No valid page numbers specified.\n",
            "PDF created successfully: edge midcap fund_2018.pdf\n",
            "done\n",
            "Selected pages saved to edge midcap fund_2018.pdf\n",
            "PDF created successfully: edge midcap fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874523000348/primary-document.htm\n",
            "2018-08-31\n",
            "==============================\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874522000172/primary-document.htm\n",
            "2018-08-31\n",
            "==============================\n",
            " =============== Finished file : P665.txt =================\n",
            "80  ========  P267.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to eaton vance tax-managed growth fund 1.2_2018.pdf\n",
            "PDF created successfully: eaton vance tax-managed growth fund 1.2_2018.pdf\n",
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-397a134dec81>:123: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ranking['n_children']=ranking.node.apply(lambda x:len(x.children))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.sec.gov/Archives/edgar/data/745463/000119312524050062/d627480dncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P267.txt =================\n",
            "81  ========  P714.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to emerald insights fund_2018.pdf\n",
            "PDF created successfully: emerald insights fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/915802/000139834423012831/fp0084043-1_ncsr.htm\n",
            "2018-04-30\n",
            "==============================\n",
            " =============== Finished file : P714.txt =================\n",
            "82  ========  P121.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P121.txt =================\n",
            "83  ========  P162.txt\n",
            "couldn't retrive from edgar database\n",
            "84  ========  P85.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P85.txt =================\n",
            "85  ========  P637.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2022-07-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-07-31\n",
            "couldn't retrive from edgar database\n",
            "86  ========  P615.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "87  ========  P739.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-03-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P739.txt =================\n",
            "88  ========  P367.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "couldn't retrive from edgar database\n",
            "89  ========  P104.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to world precious minerals fund_2018.pdf\n",
            "PDF created successfully: world precious minerals fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/101507/000143510924000085/primary-document.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P104.txt =================\n",
            "90  ========  P102.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to world precious minerals fund_2018.pdf\n",
            "PDF created successfully: world precious minerals fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/101507/000143510924000085/primary-document.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P102.txt =================\n",
            "91  ========  P669.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to basic materials fund_2018.pdf\n",
            "PDF created successfully: basic materials fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/899148/000139834423011522/fp0082719-6_ncsr.htm\n",
            "2018-03-29\n",
            "==============================\n",
            " =============== Finished file : P669.txt =================\n",
            "92  ========  P257.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P257.txt =================\n",
            "93  ========  P230.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-06-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P230.txt =================\n",
            "94  ========  P610.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "couldn't retrive from edgar database\n",
            "95  ========  P108.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "year 2018 found ...\n",
            "Selected pages saved to eaton vance atlanta capital focused growth fund_2018.pdf\n",
            "PDF created successfully: eaton vance atlanta capital focused growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/102816/000119312523283201/d584117dncsr.htm\n",
            "2018-09-30\n",
            "==============================\n",
            " =============== Finished file : P108.txt =================\n",
            "96  ========  P251.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P251.txt =================\n",
            "97  ========  P253.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-03-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to invesco energy fund_2018.pdf\n",
            "PDF created successfully: invesco energy fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/725781/000119312523179699/d462907dncsr.htm\n",
            "2018-04-30\n",
            "==============================\n",
            " =============== Finished file : P253.txt =================\n",
            "98  ========  P33.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity strategic dividend & income fund_2018.pdf\n",
            "PDF created successfully: fidelity strategic dividend & income fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/35315/000003531524000085/filing7221.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P33.txt =================\n",
            "99  ========  P80.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-06-30\n",
            "year 2018 found ...\n",
            "Selected pages saved to ab select us equity portfolio_2018.pdf\n",
            "PDF created successfully: ab select us equity portfolio_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/81443/000119312523226225/d507472dncsr.htm\n",
            "2018-06-30\n",
            "==============================\n",
            " =============== Finished file : P80.txt =================\n",
            "100  ========  P656.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to midcap value fund i_2018.pdf\n",
            "PDF created successfully: midcap value fund i_2018.pdf\n",
            "done\n",
            "Selected pages saved to midcap value fund i_2018.pdf\n",
            "PDF created successfully: midcap value fund i_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874523000409/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874522000215/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P656.txt =================\n",
            "101  ========  P715.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to ultra-small company fund_2018.pdf\n",
            "PDF created successfully: ultra-small company fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/916006/000119312523228439/d480918dncsr.htm\n",
            "2018-06-30\n",
            "==============================\n",
            " =============== Finished file : P715.txt =================\n",
            "102  ========  P663.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to real estate securities fund_2018.pdf\n",
            "PDF created successfully: real estate securities fund_2018.pdf\n",
            "done\n",
            "Selected pages saved to real estate securities fund_2018.pdf\n",
            "PDF created successfully: real estate securities fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874523000409/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874522000215/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P663.txt =================\n",
            "103  ========  P15.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-15\n",
            "year 2018 found ...\n",
            "Unable to create PDF from webpage. Error: Command failed: /usr/bin/wkhtmltopdf --quiet https://www.sec.gov/Archives/edgar/data/22370/000114544318000826/d349722.htm john hancock seaport long/short fund_2018.pdf\n",
            "Check whhtmltopdf output without 'quiet' option\n",
            "[Errno 2] No such file or directory: 'john hancock seaport long/short fund_2018.pdf' \n",
            "done\n",
            " ============= Error encountered ======== no such file: 'john hancock seaport long/short fund_2018.pdf'\n",
            " =============== Finished file : P15.txt =================\n",
            "104  ========  P730.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P730.txt =================\n",
            "105  ========  P231.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-05-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to amg managers cadence mid cap fund_2018.pdf\n",
            "PDF created successfully: amg managers cadence mid cap fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/720309/000119312520203950/d945404dncsr.htm\n",
            "2018-05-31\n",
            "==============================\n",
            " =============== Finished file : P231.txt =================\n",
            "106  ========  P661.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P661.txt =================\n",
            "107  ========  P45.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2022-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P45.txt =================\n",
            "108  ========  P171.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "couldn't retrive from edgar database\n",
            "109  ========  P78.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P78.txt =================\n",
            "110  ========  P749.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P749.txt =================\n",
            "111  ========  P282.txt\n",
            "couldn't retrive from edgar database\n",
            "112  ========  P435.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P435.txt =================\n",
            "113  ========  P13.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P13.txt =================\n",
            "114  ========  P402.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "115  ========  P84.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P84.txt =================\n",
            "116  ========  P723.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P723.txt =================\n",
            "117  ========  P264.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to financial industries fund_2018.pdf\n",
            "PDF created successfully: financial industries fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/743861/000168386323008304/f36933d1.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P264.txt =================\n",
            "118  ========  P95.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to ultra fund_2018.pdf\n",
            "PDF created successfully: ultra fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/100334/000010033423000073/acmf103123n-csr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P95.txt =================\n",
            "119  ========  P259.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-05-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P259.txt =================\n",
            "120  ========  P410.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P410.txt =================\n",
            "121  ========  P668.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to electronics fund_2018.pdf\n",
            "PDF created successfully: electronics fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/899148/000139834423011522/fp0082719-6_ncsr.htm\n",
            "2018-03-29\n",
            "==============================\n",
            " =============== Finished file : P668.txt =================\n",
            "122  ========  P696.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-11-30\n",
            "year 2018 found ...\n",
            "Selected pages saved to ab equity income fund inc_2018.pdf\n",
            "PDF created successfully: ab equity income fund inc_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/910036/000119312524024130/d511673dncsr.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P696.txt =================\n",
            "123  ========  P57.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-11-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P57.txt =================\n",
            "124  ========  P19.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity series commodity strategy fund_2018.pdf\n",
            "PDF created successfully: fidelity series commodity strategy fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/28540/000002854023000036/filing7031.htm\n",
            "2018-07-31\n",
            "==============================\n",
            " =============== Finished file : P19.txt =================\n",
            "125  ========  P700.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P700.txt =================\n",
            "126  ========  P256.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to vanguard lifestrategy growth fund_2018.pdf\n",
            "PDF created successfully: vanguard lifestrategy growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/736054/000110465923129659/tm2331781d3_ncsr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P256.txt =================\n",
            "127  ========  P436.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "128  ========  P613.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "129  ========  P48.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to neuberger berman real estate fund_2018.pdf\n",
            "PDF created successfully: neuberger berman real estate fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/44402/000089843223000752/formn-csr.htm\n",
            "2018-08-31\n",
            "==============================\n",
            " =============== Finished file : P48.txt =================\n",
            "130  ========  P415.txt\n",
            "couldn't retrive from edgar database\n",
            "131  ========  P302.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P302.txt =================\n",
            "132  ========  P211.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P211.txt =================\n",
            "133  ========  P725.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P725.txt =================\n",
            "134  ========  P369.txt\n",
            "couldn't retrive from edgar database\n",
            "135  ========  P117.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-11-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P117.txt =================\n",
            "136  ========  P600.txt\n",
            "couldn't retrive from edgar database\n",
            "137  ========  P99.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to select fund_2018.pdf\n",
            "PDF created successfully: select fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/100334/000010033423000073/acmf103123n-csr.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P99.txt =================\n",
            "138  ========  P417.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "couldn't retrive from edgar database\n",
            "139  ========  P247.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-04-30\n",
            "year 2018 found ...\n",
            "Selected pages saved to invesco mid cap growth fund_2018.pdf\n",
            "PDF created successfully: invesco mid cap growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/725781/000119312519190272/d766243dncsr.htm\n",
            "2018-04-30\n",
            "==============================\n",
            " =============== Finished file : P247.txt =================\n",
            "140  ========  P9.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P9.txt =================\n",
            "141  ========  P707.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P707.txt =================\n",
            "142  ========  P284.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-07-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-07-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P284.txt =================\n",
            "143  ========  P52.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P52.txt =================\n",
            "144  ========  P694.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to gabelli global content & connectivity fund_2018.pdf\n",
            "PDF created successfully: gabelli global content & connectivity fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/909504/000182912624001450/globalseries_ncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P694.txt =================\n",
            "145  ========  P101.txt\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P101.txt =================\n",
            "146  ========  P412.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-04-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-04-30\n",
            "couldn't retrive from edgar database\n",
            "147  ========  P296.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to jpmorgan investor growth fund_2018.pdf\n",
            "PDF created successfully: jpmorgan investor growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/763852/000119312523227041/d507370dncsr.htm\n",
            "2018-06-30\n",
            "==============================\n",
            " =============== Finished file : P296.txt =================\n",
            "148  ========  P728.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P728.txt =================\n",
            "149  ========  P47.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to neuberger berman focus fund_2018.pdf\n",
            "PDF created successfully: neuberger berman focus fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/44402/000089843223000752/formn-csr.htm\n",
            "2018-08-31\n",
            "==============================\n",
            " =============== Finished file : P47.txt =================\n",
            "150  ========  P290.txt\n",
            "couldn't retrive from edgar database\n",
            "151  ========  P22.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P22.txt =================\n",
            "152  ========  P1105.txt\n",
            "couldn't retrive from edgar database\n",
            "153  ========  P240.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to fidelity advisor equity growth fund_2018.pdf\n",
            "PDF created successfully: fidelity advisor equity growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/722574/000072257424000054/filing7223.htm\n",
            "2018-11-30\n",
            "==============================\n",
            " =============== Finished file : P240.txt =================\n",
            "154  ========  P443.txt\n",
            "couldn't retrive from edgar database\n",
            "155  ========  P607.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-09-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-09-30\n",
            "couldn't retrive from edgar database\n",
            "156  ========  P704.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to praxis small cap index fund_2018.pdf\n",
            "PDF created successfully: praxis small cap index fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/912900/000139834424005320/fp0086655-3_ncsr.htm\n",
            "2018-12-31\n",
            "==============================\n",
            " =============== Finished file : P704.txt =================\n",
            "157  ========  P403.txt\n",
            "Missing file or Different structure txt file\n",
            "158  ========  P238.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2021-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2020-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-11-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-11-30\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P238.txt =================\n",
            "159  ========  P295.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to jpmorgan small cap growth fund_2018.pdf\n",
            "PDF created successfully: jpmorgan small cap growth fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/763852/000119312523227041/d507370dncsr.htm\n",
            "2018-06-30\n",
            "==============================\n",
            " =============== Finished file : P295.txt =================\n",
            "160  ========  P260.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-06-30\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P260.txt =================\n",
            "161  ========  P233.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-05-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-05-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to amg managers cadence mid cap fund_2018.pdf\n",
            "PDF created successfully: amg managers cadence mid cap fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/720309/000119312520203950/d945404dncsr.htm\n",
            "2018-05-31\n",
            "==============================\n",
            " =============== Finished file : P233.txt =================\n",
            "162  ========  P64.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P64.txt =================\n",
            "163  ========  P303.txt\n",
            "couldn't retrive from edgar database\n",
            "164  ========  P713.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to vulcan value partners small cap fund_2018.pdf\n",
            "PDF created successfully: vulcan value partners small cap fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/915802/000139834423012831/fp0084043-1_ncsr.htm\n",
            "2018-04-30\n",
            "==============================\n",
            " =============== Finished file : P713.txt =================\n",
            "165  ========  P165.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "couldn't retrive from edgar database\n",
            "166  ========  P602.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "167  ========  P660.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-10-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-10-31\n",
            "year 2018 found ...\n",
            "Selected pages saved to largecap growth fund i_2018.pdf\n",
            "PDF created successfully: largecap growth fund i_2018.pdf\n",
            "done\n",
            "Selected pages saved to largecap growth fund i_2018.pdf\n",
            "PDF created successfully: largecap growth fund i_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874523000409/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874522000215/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P660.txt =================\n",
            "168  ========  P414.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-08-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-03-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-08-31\n",
            "couldn't retrive from edgar database\n",
            "169  ========  P42.txt\n",
            "year 2018 found ...\n",
            "Selected pages saved to franklin utilities fund_2018.pdf\n",
            "PDF created successfully: franklin utilities fund_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/38721/000186842023000188/primary-document.htm\n",
            "2018-09-30\n",
            "==============================\n",
            " =============== Finished file : P42.txt =================\n",
            "170  ========  P243.txt\n",
            "couldn't retrive from edgar database\n",
            "171  ========  P404.txt\n",
            "Missing file or Different structure txt file\n",
            "172  ========  P167.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-02-29\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-02-28\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-02-28\n",
            "couldn't retrive from edgar database\n",
            "173  ========  P275.txt\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2019-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2018-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2017-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2016-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2015-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2014-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2013-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2012-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2011-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2010-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2009-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2008-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2007-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2006-12-31\n",
            "list.remove(x): x not in list\n",
            "Can't find wanted fund in 2005-12-31\n",
            "year 2018 not found ..!\n",
            " =============== Finished file : P275.txt =================\n",
            "174  ========  P658.txt\n",
            "year 2018 found ...\n",
            "No valid page numbers specified.\n",
            "PDF created successfully: strategic asset management conservative growth portfolio_2018.pdf\n",
            "done\n",
            "No valid page numbers specified.\n",
            "PDF created successfully: strategic asset management conservative growth portfolio_2018.pdf\n",
            "done\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874523000409/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            "https://www.sec.gov/Archives/edgar/data/898745/000089874522000215/primary-document.htm\n",
            "2018-10-31\n",
            "==============================\n",
            " =============== Finished file : P658.txt =================\n",
            "175  ========  P438.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k6gCoursIVM",
        "outputId": "0cf6f413-fbb1-448d-f018-f87d004ba72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(157, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.to_csv('total_df.csv',index=False)"
      ],
      "metadata": {
        "id": "3Dx29ykPsVBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(db_issue)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrY6QgAr4nZx",
        "outputId": "44917153-e0ed-4d4d-8c43-b3ef1c95e179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(missing_funds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt4NIbkj4neV",
        "outputId": "c5fc55cb-8d0f-435c-fecd-b3cc50ef8a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1767"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(structure_failure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSjyoDDg5A27",
        "outputId": "c345d3e8-e8e9-4733-f419-a160f508597a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAeuN8JTmTuw"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2lXa49Nm4rl"
      },
      "outputs": [],
      "source": [
        "#!pip install rouge\n",
        "import nltk,re\n",
        "from nltk.translate.bleu_score import sentence_bleu,SmoothingFunction\n",
        "from rouge import Rouge\n",
        "import pandas as pd\n",
        "import sys\n",
        "sys.setrecursionlimit(5000)\n",
        "\n",
        "\n",
        "\n",
        "def calculate_scores(df):\n",
        "    bleu_scores = []\n",
        "    rouge_scores = []\n",
        "    recall_scores = []\n",
        "    precision_scores = []\n",
        "    included_scores = []\n",
        "\n",
        "    rouge = Rouge()\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # ground = row['extracted']\n",
        "        # ground = re.sub(\"[^a-z0-9]\\s\",' ',' '.join(ground.split()).lower())\n",
        "        # truth = row['truth']\n",
        "        # truth = re.sub(\"[^a-z0-9]\\s\",' ',' '.join(truth.split()).lower())\n",
        "\n",
        "        # Calculate BLEU score\n",
        "        # bleu = sentence_bleu([truth.split()], ground.split())\n",
        "\n",
        "\n",
        "        try:\n",
        "          extracted = row['extracted']\n",
        "          extracted = ' '.join(re.sub(\"[^a-z0-9]\",' ',' '.join(extracted.split()).lower()).split())\n",
        "          truth = row['truth']\n",
        "          truth = ' '.join(re.sub(\"[^a-z0-9]\",' ',' '.join(truth.split()).lower()).split())\n",
        "\n",
        "\n",
        "\n",
        "          # Define a smoothing function\n",
        "          smooth = SmoothingFunction().method1\n",
        "          # Calculate BLEU score with smoothing\n",
        "          bleu = sentence_bleu([truth.split()], extracted.split(), smoothing_function=smooth)\n",
        "          # Calculate ROUGE score\n",
        "          rouge_score = rouge.get_scores(extracted, truth)\n",
        "\n",
        "\n",
        "        except:\n",
        "          extracted = row['extracted']\n",
        "          extracted = re.sub(\"[^a-z0-9]\\s\",' ',' '.join(extracted.split()).lower())\n",
        "          truth = row['truth']\n",
        "          truth = re.sub(\"[^a-z0-9]\\s\",' ',' '.join(truth.split()).lower())\n",
        "\n",
        "          bleu = sentence_bleu([truth.split()], extracted.split(), smoothing_function=smooth)\n",
        "          # Calculate ROUGE score\n",
        "          rouge_score = rouge.get_scores(extracted, truth)\n",
        "\n",
        "        # append outside the loop\n",
        "        rouge_scores.append(rouge_score[0]['rouge-l']['f'])\n",
        "        bleu_scores.append(bleu)\n",
        "\n",
        "        x = ' '.join(re.sub(\"[^a-z0-9]\",' ',' '.join(row['extracted'].split()).lower()).split()) # x is the automatic extracted\n",
        "        y = ' '.join(re.sub(\"[^a-z0-9]\",' ',' '.join(row['truth'].split()).lower()).split()) # y is the annotation\n",
        "        included_scores.append(y in x)\n",
        "        # calculate precision and recall\n",
        "        recall_scores.append(calculate_recall(x,y))\n",
        "        precision_scores.append(calculate_precision(x,y))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Create a new dataframe with BLEU and ROUGE scores\n",
        "    result_df = df.copy().drop(['unwanted'],axis=1)\n",
        "    result_df['bleu'] = bleu_scores\n",
        "    result_df['rouge'] = rouge_scores\n",
        "    result_df['recall'] = recall_scores\n",
        "    result_df['precision'] = precision_scores\n",
        "\n",
        "    result_df['included'] = included_scores # check if the reference as whole is part of the extracted (this is when extracted is covering the reference but )\n",
        "\n",
        "    return result_df\n",
        "\n",
        "# Calculate scores\n",
        "# result_df = calculate_scores(ann).sort_values(by=['rouge','bleu'],ascending=False)\n",
        "# result_df = calculate_scores(total_df).sort_values(by=['rouge','bleu'],ascending=False)\n",
        "result_df = calculate_scores(df1).sort_values(by=['rouge','bleu'],ascending=False)\n",
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMMo4ICLqygT",
        "outputId": "e74d10be-4cb9-44a6-f6bc-2e6ee0df6317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean rouge 0.4126860729651073\n",
            "std rouge 0.36778866791703074\n",
            "mean precision 0.5449696514346191\n",
            "std precision 0.4245477561122437\n",
            "mean recall 0.5738016585155327\n",
            "std recall 0.3390437491493076\n"
          ]
        }
      ],
      "source": [
        "print(f'mean rouge {result_df.rouge.mean()}')\n",
        "print(f'std rouge {result_df.rouge.std()}')\n",
        "print(f'mean precision {result_df.precision.mean()}')\n",
        "print(f'std precision {result_df.precision.std()}')\n",
        "print(f'mean recall {result_df.recall.mean()}')\n",
        "print(f'std recall {result_df.recall.std()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pICp2ggfqyxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af68226-c641-411d-cd8b-7a1b8c28be57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "std included 0.4288588868025356\n"
          ]
        }
      ],
      "source": [
        "result_df.included.mean()\n",
        "print(f'std included {result_df.included.std()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7oqTqa_y66A"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(df.rouge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I035Id-dzB65"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(df.precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmWRBy1f2VZD"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.histplot(df.included)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYrMbmC427t_"
      },
      "outputs": [],
      "source": [
        "ax = sns.distplot(df['included'], kde=False, bins=8,color='black')\n",
        "\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.0f}\\n',\n",
        "                (p.get_x() + p.get_width() / 2, p.get_height()), ha='center', va='center', color='crimson')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZRmhB_yZv2M5",
        "TZ5yhRrQO_x7",
        "baN6tXfxd_YJ",
        "aAeuN8JTmTuw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}